{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size  price_per_person\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2          8.495000\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3          3.446667\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3          7.003333\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2         11.840000\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4          6.147500\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the tips dataset\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "# Create the price_per_person column\n",
    "tips['price_per_person'] = tips['total_bill'] / tips['size']\n",
    "\n",
    "# Show the first 5 rows of the updated dataset\n",
    "print(tips.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the tips dataset, some features that could potentially be important for predicting the tip amount are:\n",
    "\n",
    "1. Total bill: customers may tip a higher percentage for larger bills.\n",
    "2. Party size: larger parties may leave a smaller percentage tip than smaller parties.\n",
    "3. Day of the week: tipping customs may vary depending on the day of the week (e.g. weekend vs weekday).\n",
    "4. Time of day: tipping customs may vary depending on the time of day (e.g. lunch vs dinner).\n",
    "5. Gender of the server: tipping customs may vary depending on the gender of the server.\n",
    "6. Smoking section: customers in the smoking section may tip differently than those in the non-smoking section.\n",
    "7. Alcohol consumption: customers who consume alcohol may tip differently than those who don't.\n",
    "8. Customer rating: customers may tip more for excellent service and less for poor service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['total_bill', 'size'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Select the top 2 features using SelectKBest and f_regression\n",
    "X = tips.drop(['tip', 'sex', 'smoker', 'day', 'time'], axis=1)\n",
    "y = tips['tip']\n",
    "selector = SelectKBest(f_regression, k=2)\n",
    "selector.fit(X, y)\n",
    "\n",
    "# Get the indices of the top 2 features\n",
    "top_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the top 2 features\n",
    "top_features = X.columns[top_indices]\n",
    "\n",
    "# Show the top 2 features\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['total_bill', 'price_per_person'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Separate the target variable and the input features\n",
    "X = tips.drop(['tip', 'sex', 'smoker', 'day', 'time'], axis=1)\n",
    "y = tips['tip']\n",
    "\n",
    "# Instantiate a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Instantiate an RFE object with 2 features to select\n",
    "selector = RFE(model, n_features_to_select=2)\n",
    "\n",
    "# Fit the RFE selector to the data\n",
    "selector.fit(X, y)\n",
    "\n",
    "# Get the indices of the top 2 features\n",
    "top_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the top 2 features\n",
    "top_features = X.columns[top_indices]\n",
    "\n",
    "# Show the top 2 features\n",
    "print(top_features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do you think select k best and recursive feature elimination might give different answers for the top features? Does this change as you change the number of features you are selecting?\n",
    "\n",
    "SelectKBest and Recursive Feature Elimination (RFE) use different criteria to select features, which may result in different answers for the top features. SelectKBest selects the k best features based on a statistical test, such as the chi-squared test or the F-test, which measures the dependence between each feature and the target variable. On the other hand, RFE selects features by recursively removing the least important feature and re-fitting the model until the desired number of features is reached. \n",
    "\n",
    "SelectKBest is a simpler and faster method that may be appropriate when you have a large number of features and want to quickly identify the most informative ones. However, it may not perform well when the relationship between the features and the target variable is nonlinear or complex. RFE, on the other hand, can handle nonlinear and complex relationships between features and the target variable, but it can be computationally expensive and may take longer to converge to the optimal solution.\n",
    "\n",
    "As for whether the top features change when you change the number of features you are selecting, the answer is yes. When you increase the number of features you are selecting, the likelihood of finding different features increases. This is because additional features may have a stronger or weaker relationship with the target variable than the initial features, and the ranking of features may change as a result. Therefore, it is important to experiment with different numbers of features and compare the results to ensure that you are selecting the features that best fit your modeling goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "def select_kbest(X, y, k):\n",
    "    \"\"\"\n",
    "    Select the top k features from X based on univariate statistical tests.\n",
    "\n",
    "    Parameters:\n",
    "    - X: pandas DataFrame of shape (n_samples, n_features)\n",
    "        The input features to select from.\n",
    "    - y: pandas Series or array of shape (n_samples,)\n",
    "        The target variable.\n",
    "    - k: integer\n",
    "        The number of top features to select.\n",
    "\n",
    "    Returns:\n",
    "    - list of strings\n",
    "        The names of the top k features selected.\n",
    "    \"\"\"\n",
    "    # Instantiate a SelectKBest object with f_regression as the score function\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "\n",
    "    # Fit the selector to the data\n",
    "    selector.fit(X, y)\n",
    "\n",
    "    # Get the indices of the top k features\n",
    "    top_indices = selector.get_support(indices=True)\n",
    "\n",
    "    # Get the names of the top k features\n",
    "    top_features = list(X.columns[top_indices])\n",
    "\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['total_bill', 'size']\n"
     ]
    }
   ],
   "source": [
    "# Separate the target variable and the input features\n",
    "X = tips.drop(['tip', 'sex', 'smoker', 'day', 'time'], axis=1)\n",
    "y = tips['tip']\n",
    "\n",
    "# Select the top 2 features using the select_kbest function\n",
    "top_features = select_kbest(X, y, k=2)\n",
    "\n",
    "# Print the top 2 features\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a linear regression object\n",
    "estimator = LinearRegression()\n",
    "\n",
    "# Define a function to use RFE for feature selection\n",
    "def rfe(X, y, k):\n",
    "    # Instantiate a RFE object with the estimator and number of features to select\n",
    "    selector = RFE(estimator)\n",
    "    \n",
    "    # Fit the selector to the data and select the top k features\n",
    "    selector.fit(X, y)\n",
    "    top_k_features = selector.ranking_[:k]\n",
    "    \n",
    "    return top_k_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3]\n"
     ]
    }
   ],
   "source": [
    "# Select the top 2 features using the rfe function\n",
    "top_features = rfe(X, y, k=2)\n",
    "\n",
    "# Print the top 2 features\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 features using SelectKBest: Index(['Examination', 'Education', 'Catholic'], dtype='object')\n",
      "Top 3 features using Recursive Feature Elimination: Index(['Examination', 'Education', 'Infant.Mortality'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Swiss dataset from pydataset\n",
    "from pydataset import data\n",
    "df = data('swiss')\n",
    "\n",
    "if 'Region' in df.columns:\n",
    "    X = df.drop(['Fertility', 'Region'], axis=1)\n",
    "else:\n",
    "    X = df.drop(['Fertility'], axis=1)\n",
    "\n",
    "# Split the data into X (features) and y (target)\n",
    "y = df['Fertility']\n",
    "\n",
    "# Use SelectKBest to find top 3 features\n",
    "skb = SelectKBest(score_func=f_regression, k=3)\n",
    "X_new = skb.fit_transform(X, y)\n",
    "top3_skb = X.columns[skb.get_support()]\n",
    "\n",
    "# Use Recursive Feature Elimination to find top 3 features\n",
    "lr = LinearRegression()\n",
    "rfe = RFE(lr, n_features_to_select=3)\n",
    "rfe.fit(X, y)\n",
    "top3_rfe = X.columns[rfe.support_]\n",
    "\n",
    "print('Top 3 features using SelectKBest:', top3_skb)\n",
    "print('Top 3 features using Recursive Feature Elimination:', top3_rfe)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
